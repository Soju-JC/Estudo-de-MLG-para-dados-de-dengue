%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Preâmbulo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{bm}
\usepackage{float}
\usepackage[margin=1.5in]{geometry}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\let\lctau\tau % save the lowercase of '\tau'
\renewcommand{\tau}{\scalerel*{\lctau}{X}}
\renewcommand{\tablename}{\textbf{Tabela}}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\renewcommand{\contentsname}{Sumário} 

\title{MLG - Trabalho 2}
\author{José Carlos Soares Junior }
\date{Matrícula: 2017100732}

\begin{document}
\begin{titlepage}
	\begin{center}
	
	%\begin{figure}[!ht]
	%\centering
	%\includegraphics[width=2cm]{c:/ufba.jpg}
	%\end{figure}

		\Huge{UNIVERSIDADE FEDERAL DO ESPÍRITO SANTO}\\
		\large{CENTRO DE CIÊNCIAS EXATAS}\\ 
		\large{DEPARTAMENTO DE ESTATÍSTICA}\\ 
\vspace{15pt}
        
        \vspace{85pt}
        
		\textbf{\LARGE{Modelagem dos dados de 2013 referentes às notificações de dengue no estado do Espírito Santo}}
		\title{\large{Título}}
	%	\large{Modelo\\
     %   		Validação do modelo clássico}
			
	\end{center}
\vspace{1,5cm}
	
	\begin{flushright}

   \begin{list}{}{
      \setlength{\leftmargin}{4.5cm}
      \setlength{\rightmargin}{0cm}
      \setlength{\labelwidth}{0pt}
      \setlength{\labelsep}{\leftmargin}}

      \item Segundo trabalho da disciplina de MLG ministrado pelo Prof. Dr. Saulo Morellato.

      \begin{list}{}{
      \setlength{\leftmargin}{0cm}
      \setlength{\rightmargin}{0cm}
      \setlength{\labelwidth}{0pt}
      \setlength{\labelsep}{\leftmargin}}

			\item Alunos: José Carlos Soares Junior\\
			         \;\;\;\;\;\;\;\;\;\;\;\;\;     Luiz Felipe Figueiredo\\
			         \;\;\;\;\;\;\;\;\;\;\;\;\;     Mariana Machado Matheus 
            \item Orientador: Prof. Dr. Saulo Morellato\

      \end{list}
   \end{list}
\end{flushright}
\vspace{1cm}
\begin{center}
		\vspace{\fill}
		 Abril\\
		 2021
			\end{center}
\end{titlepage}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Pacotes %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,include=FALSE>>=
loadlibrary <- function(x){
  
  if (!require(x,character.only = TRUE)) {
    install.packages(x,dependencies = T)
    if(!require(x, character.only = TRUE)) 
      stop("Package not found")
  }
}

packages <- c(
  "tidyverse",
  "readxl",
  "janitor",
  "skimr",
  "lubridate",
  "summarytools",
  "magrittr", 
  "pipeR",
  "knitr",
  "viridis",
  "cowplot",
  "tidyr",
  "reshape2",
  "VIM",
  "mice",
  "VGAM",
  "nlme",
  "visreg",
  "lme4",
  "glmnet",
  "leaps",
  "glmmLasso",
  "glmmTMB",
  "mgcv",
  "writexl",
  "car",
  "ggcorrplot",
  "hnp", 
  "kableExtra",
  "stargazer"
)

lapply(packages, loadlibrary) # carrega pacotes

# carrega dados
dados <- read_excel("dados.xlsx")
dados_2013 <- subset(dados,ano == 2013)
dados_2013 <- dados_2013[,-28] #sem id
data<-subset(dados,ano == 2013)
data<-data[,-28] #sem id
########## modelos definidos ###########

##### Poisson
require(MASS)
data <- read_excel("dados.xlsx")

modelo_completo <- glm(dengue~IntCdAtBca +
                        CobCondSaud +
                        CobAtencBsca +
                        temp_p10 +
                        temp +
                        temp_p90 +
                        precip +
                        umid_p10 +
                        umid +
                        umid_p90 +
                        alt +
                        ifdm_saude +
                        ifdm_edu +
                        ifdm_emprend +
                        cobveg +
                        expcosteira +
                        ivc +
                        Pobr +
                        ExpAnosEstud +
                        urb +
                        menor15 +
                        maior65 +
                        adultos +
                        pop +
                        area +
                        dens,
                      family=poisson,
                      data=data
                      )

modelo_selecionado <- stepAIC(modelo_completo)

modelo_corr<- glm(dengue~CobCondSaud +
                    CobAtencBsca +
                    temp_p90 +
                    precip +
                    umid +
                    ifdm_saude +
                    ifdm_emprend +
                    cobveg +
                    expcosteira +
                    ivc +
                    ExpAnosEstud +
                    urb +
                    maior65 +
                    adultos +
                    dens,
                  family=poisson,
                  data=data
                  )

modelo_selecionado_corr <- stepAIC(modelo_corr)

modelo_corr_offset<- glm(dengue~CobCondSaud + 
                           CobAtencBsca +
                           temp_p90 + 
                           precip +
                           umid +
                           ifdm_saude +
                           ifdm_emprend +
                           cobveg + 
                           expcosteira + 
                           ivc +
                           ExpAnosEstud +
                           urb +
                           maior65 +
                           adultos +
                           dens + 
                           offset(log(pop)), 
                         family=poisson, 
                         data=data
                         )

modelo_selecionado_corr_offset <- stepAIC(modelo_corr_offset)

@

\tableofcontents  % sumário

% Formato do chunk a ser usado:

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,fig.height=8,fig.width=12>>=

@

%%%%%%%%%%%%%%%%%%%%%%%%%%% Descrição dos dados %%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\newpage
\section{\textbf{{\LARGE\textbf{Descrição dos dados}}}}

\textbf{IntCdAtBca} - Proporção de internações por condições sensíveis à Atenção Basica;

\noindent
\textbf{CobCondSaud} - Cobertura de acompanhamento das condicionalidades de saúde do Programa Bolsa Família;

\noindent
\textbf{CobAtBas} - Cobertura das equipes atenção básica municipal expresso em percentual da cobertura populacional alcançada pela Atenção Básica;

\noindent
\textbf{temp} - temperatura média anual;

\noindent
$\mathbf{temp\_p10}$ - percentil $10$ das temperaturas durante o ano;

\noindent
$\mathbf{temp\_p90}$ - percentil $90$ das temperaturas durante o ano;

\noindent
\textbf{precip} - precipitação pluviométrica acumulada anual;

\noindent
\textbf{umid} - média anual da umidade relativa do ar;

\noindent
$\mathbf{umid\_p10}$ - percentil $10$ da umidade relativa do ar durante o ano;

\noindent
$\mathbf{umid\_p90}$ - percentil $90$ da umidade relativa do ar durante o ano;

\noindent
\textbf{alt} - altitude da sede municipal;

\noindent
\textbf{ifdm\_saude} - Índice Firjan de Desenvolvimento Municipal-IFDM para saúde;

\noindent
\textbf{ifdm\_edu} - Índice Firjan de Desenvolvimento Municipal-IFDM para educação;

\noindent
\textbf{ifdm\_emprend} - Índice Firjan de Desenvolvimento Municipal-IFDM de emprego e renda;

\noindent
\textbf{cobveg} - índice de cobertura vegetal;

\noindent
\textbf{expcosteira} - ídice de exposição costeira;

\noindent
\textbf{ivc} - índice de vulnerabilidade climática;

\noindent
\textbf{pobr} - proporção de pobres;

\noindent
\textbf{ExpAnosEstud} - expectativa de anos de estudo;

\noindent
\textbf{urb} - proporção da população que reside em zona urbana;

\noindent
$\mathbf{menor15}$ - proporção da população com menos de $15$ anos;

\noindent
$\mathbf{maior65}$ - proporção da população com mais de $65$ anos;

\noindent
\textbf{adultos} - proporção da população entre $15$ e $65$ anos;

\noindent
\textbf{pop} - população do município;

\noindent
\textbf{area} - área do município;

\noindent
\textbf{dens} - densidade populacional (pop\/area);

\noindent
\textbf{id} - identificação;

\noindent
\textbf{ano} - ano referente às informações; e

\noindent
\textbf{dengue} - número de notificações municipais de dengue.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Descritiva %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\newpage
\section{{\LARGE\textbf{Análise exploratória}}}

A dengue é uma doença que por melhor que tenham sido as ações da humanidade para lidar com ela, sempre tem sido parte de nossas vidas, tendo perdurado como um dos maiores problemas de saúde pública já visto.

Este trabalho consiste em construir modelos de regressão com interesse nas notificações de dengue dos municípios do estado do Espirito Santo, sendo os dados utilizados contendo várias informações sociais ou até mesmo de origem natural como temperatura e umidade do ar. Estes dados são referentes ao ano de $2013$, onde foi quando o Espirito Santo enfrentou a pior crise epidêmica de dengue se comparado com os anos seguintes, até que foi passada pela crise de $2019$.

\newpage
Mas se olharmos para o número de notificações daquele ano por município, quais tiveram mais notificações ? 

%%%%%% Notificações de dengue por municipio %%%%%%%

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,fig.width= 8, fig.height= 11, fig.align= "center", fig.pos='H'>>=
ggplot(dados_2013,aes(x = Municipio, y = dengue)) + 
  geom_histogram(fill = rgb(0.3,0.7,0.5,0.9), stat= "identity") + 
  labs(x = "Municipio", y = "\nNotificações de dengue") + 
  coord_flip() + 
  scale_y_continuous(expand = c(0,.5),
                     limits = c(0,25000),
                     breaks = seq(0,25000,2500)) + 
  theme(axis.text.x  = element_text(angle=45, hjust = 1)) +
  scale_x_discrete(expand = c(0,.5)) 
@
\textbf{Figura 1:} Notificações de dengue por municípios do estado do Espírito Santo.

\newpage
Podemos observar pela \emph{Figura 1} que os municípios que tiveram mais notificações de dengue no ano de $2013$ foram os seguintes:

\begin{itemize}
  \item Vitória
  \item Vila Velha
  \item Viana
  \item Serra
  \item Cariacica
  \item Cachoeiro de Itapemirim
\end{itemize}

Com exceção de Cachoeiro de Itapemirim, os demais municípios que tiveram mais notificações são graficamente cidades extremamente próximas concentradas ao redor da capital Vitória, o qual dentre todos, teve o maior número de notificações de dengue registrado.

Pensando que talvez baixos índices referentes à saúde pública, ou índices sociais e educacionais possam ter alguma influência no número de notificações, o que podemos encontrar nos dados ?

%%%%%%% Tabelas e gráficos de índices sociais e educacionais %%%%%%%

\begin{table}[H]
\caption{Estatísticas básicas das variáveis de índices sociais e educacionais:}
\begin{center}
\begin{tabular}{cc|c|c|c|c|c|c}
\hline
\multicolumn{1}{c|}{Variável}     & Min  & 1° quartil & Mediana & Média & 3° quartil & Máx   & Desvio \\ \hline
\multicolumn{1}{c|}{IntCdAtBca}   & 16.5 & 25.9       & 31.3    & 33.7  & 38.7       & 63.9  & 10.5   \\
\multicolumn{1}{c|}{CobCondSaud}  & 35.3 & 66.8       & 78.1    & 75.5  & 87.1       & 99.0  & 14.6   \\
\multicolumn{1}{c|}{CobAtencBsca} & 0.0  & 85.0       & 100.0   & 87.2  & 100.0      & 100.0 & 21.3   \\
\multicolumn{1}{c|}{ifdm\_saude}  & 54.6 & 74.1       & 82.9    & 80.0  & 86.4       & 92.5  & 8.7    \\
\multicolumn{1}{c|}{ifdm\_edu}    & 72.9 & 79.5       & 83.5    & 83.2  & 86.7       & 91.7  & 4.7    \\
\multicolumn{1}{c|}{ifdm\_emprend}                    & 28.4 & 50.6       & 58.5    & 59.0  & 66.1       & 89.5  & 11.6   \\ \cline{1-8} 
\end{tabular}
\end{center}
\end{table}

Ao olharmos para as informações da \emph{Tabela 1}, observamos valores centrais de média e mediana bem próximos indicando que os dados desses índices nos municípios não fogem tanto dos valores centrais, havendo uma maior diferênça quanto aos valores centrais na variável \_CobAtencBsca\_.

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,fig.width= 10, fig.height= 7, fig.align= "center", fig.pos='H'>>=

dados_2013_boxplot <- dados_2013
attach(dados_2013_boxplot)

             ########## IntCdAtBca ##########

# Cria IntCdAtBca_indice
dados_2013_boxplot$IntCdAtBca_indice <- 
  ifelse(IntCdAtBca < 34, 1, 0)

dados_2013_boxplot$IntCdAtBca_indice <- 
  fct_recode(as.factor(dados_2013_boxplot$IntCdAtBca_indice), 
             "sim" = "1",
             "não" = "0")

#Boxplot IntCdAtBca_indice e dengue
# dev.new(width=6,height=3)
plot1 <- ggplot(dados_2013_boxplot[-78,], 
       aes(x = IntCdAtBca_indice,
           y = dengue,
           group = IntCdAtBca_indice, 
           fill = IntCdAtBca_indice)
       ) + 
geom_boxplot(notch = FALSE) + 
scale_y_continuous(breaks = seq(0,20500,500)) + 
labs(y = "Notificações de dengue\n",
     x = "\nMunicípio com IntCdAtBca < 34 ?") + 
guides(fill = FALSE) 
             
             ########## CobCondSaud ##########

#Cria CobCondSaud_indice
dados_2013_boxplot$CobCondSaud_indice <- 
  ifelse(CobCondSaud < 76, 1, 0)

dados_2013_boxplot$CobCondSaud_indice <- 
  fct_recode(as.factor(dados_2013_boxplot$CobCondSaud_indice), 
             "sim" = "1",
             "não" = "0")

#Boxplot CobCondSaud_indice e dengue
# dev.new(width=6,height=3)
plot2 <- ggplot(dados_2013_boxplot[-78,], 
       aes(x = CobCondSaud_indice,
           y = dengue,
           group = CobCondSaud_indice, 
           fill = CobCondSaud_indice)
) + 
  geom_boxplot(notch = FALSE) + 
  scale_y_continuous(breaks = seq(0,20500,500)) + 
  labs(y = "Notificações de dengue\n",
       x = "\nMunicípio com CobCondSaud < 76 ?") + 
  guides(fill = FALSE)

            ########## CobAtencBsca ##########

#Cria CobAtencBsca_indice
dados_2013_boxplot$CobAtencBsca_indice <- 
  ifelse(CobAtencBsca < 100, 1, 0)

dados_2013_boxplot$CobAtencBsca_indice <- 
  fct_recode(as.factor(dados_2013_boxplot$CobAtencBsca_indice), 
             "sim" = "1",
             "não" = "0")

#Boxplot CobAtencBsca_indice e dengue
# dev.new(width=6,height=3)
plot3 <- ggplot(dados_2013_boxplot[-78,], 
       aes(x = CobAtencBsca_indice,
           y = dengue,
           group = CobAtencBsca_indice, 
           fill = CobAtencBsca_indice)
) + 
  geom_boxplot(notch = FALSE) + 
  scale_y_continuous(breaks = seq(0,20500,500)) + 
  labs(y = "Notificações de dengue\n", 
       x = "\nMunicípio com CobAtencBsca < 100 ?") + 
  guides(fill = FALSE)

               ########## ifdm_saude ##########

#Cria ifdm_saude_indice
dados_2013_boxplot$ifdm_saude_indice <- 
  ifelse(ifdm_saude < 80, 1, 0)

dados_2013_boxplot$ifdm_saude_indice <- 
  fct_recode(as.factor(dados_2013_boxplot$ifdm_saude_indice), 
             "sim" = "1",
             "não" = "0")

#Boxplot ifdm_saude_indice e dengue
# dev.new(width=6,height=3)
plot4 <- ggplot(dados_2013_boxplot[-78,], 
       aes(x = ifdm_saude_indice,
           y = dengue,
           group = ifdm_saude_indice, 
           fill = ifdm_saude_indice)
) + 
  geom_boxplot(notch = FALSE) + 
  scale_y_continuous(breaks = seq(0,20500,500)) + 
  labs(y = "Notificações de dengue\n", 
       x = "\nMunicípio com ifdm_saude < 80 ?") + 
  guides(fill = FALSE) 

                ########## ifdm_edu ##########

#Cria ifdm_edu_indice
dados_2013_boxplot$ifdm_edu_indice <- 
  ifelse(ifdm_edu < 83, 1, 0)

dados_2013_boxplot$ifdm_edu_indice <- 
  fct_recode(as.factor(dados_2013_boxplot$ifdm_edu_indice), 
             "sim" = "1",
             "não" = "0")

#Boxplot ifdm_edu_indice e dengue
# dev.new(width=6,height=3)
plot5 <- ggplot(dados_2013_boxplot[-78,], 
       aes(x = ifdm_edu_indice,
           y = dengue,
           group = ifdm_edu_indice, 
           fill = ifdm_edu_indice)
) + 
  geom_boxplot(notch = FALSE) + 
  scale_y_continuous(breaks = seq(0,20500,500)) + 
  labs(y = "Notificações de dengue\n", 
       x = "\nMunicípio com ifdm_edu < 83 ?") + 
  guides(fill = FALSE) 

              ########## ifdm_emprend ##########

#Cria ifdm_emprend_indice
dados_2013_boxplot$ifdm_emprend_indice <- 
  ifelse(ifdm_emprend < 59, 1, 0)

dados_2013_boxplot$ifdm_emprend_indice <- 
  fct_recode(as.factor(dados_2013_boxplot$ifdm_emprend_indice), 
             "sim" = "1",
             "não" = "0")

#Boxplot ifdm_emprend_indice e dengue
# dev.new(width=6,height=3)
plot6 <- ggplot(dados_2013_boxplot[-78,], 
       aes(x = ifdm_emprend_indice,
           y = dengue,
           group = ifdm_emprend_indice, 
           fill = ifdm_emprend_indice)
) + 
  geom_boxplot(notch = FALSE) + 
  scale_y_continuous(breaks = seq(0,20500,500)) + 
  labs(y = "Notificações de dengue\n", 
       x = "\nMunicípio com ifdm_emprend < 59 ?") + 
  guides(fill = FALSE) 

plot_grid(plot1, 
          plot2,
          plot3, 
          plot4, 
          plot5, 
          plot6,
          labels = c("A","B","C","D","E","F"))

detach(dados_2013_boxplot)

@
\textbf{Figura 2A:} Boxplot do número de notificações de dengue e o índice \_IntCdAtBca\_ avaliado em dois grupos (acima da média e abaixo da média), sem considerar o município Vitória.  

\textbf{Figura 2B:} Boxplot do número de notificações de dengue e o índice \_CobCondSaud\_ avaliado em dois grupos (acima da média e abaixo da média), sem considerar o município Vitória.

\textbf{Figura 2C:} Boxplot do número de notificações de dengue e o índice \_CobAtencBsca\_ avaliado em dois grupos (acima da mediana e abaixo da mediana), sem considerar o município Vitória.

\textbf{Figura 2D:} Boxplot do número de notificações de dengue e o índice \_ifdm saude\_ avaliado em dois grupos (acima da média e abaixo da média), sem considerar o município Vitória.

\textbf{Figura 2E:} Boxplot do número de notificações de dengue e o índice \_ifdm edu\_ avaliado em dois grupos (acima da média e abaixo da média), sem considerar o município Vitória.

\textbf{Figura 2F:} Boxplot do número de notificações de dengue e o índice \_ifdm emprend\_ avaliado em dois grupos (acima da média e abaixo da média), sem considerar o município Vitória.

\newpage
Podemos observar que nas \emph{Figuras 2A, 2B, 2C e 2E} que o grupo dos municípios que tiveram os referentes índices abaixo da média (mediana para a \emph{Figura 2C}) naquele ano teve mais municípios com notificações extremas de dengue, se comparado com o grupo de municípios com os índices acima do valor central em questão. Além disso, a mediana de ambos os grupos não parece ter uma diferença muito discrepante, com exceção das medianas no índice CobAtencBsca, onde o grupo dos municípios com índice abaixo da mediana do estado teve a mediana consideralmente maior que a do grupo de municípios de índice de mediana acima.

Por outro lado, nas \emph{Figuras 2D e 2F} o grupo dos municípios que tiveram os referentes índices acima ou igual à média naquele ano teve mais municípios com notificações extremas de dengue, se comparado com o grupo de municípios com os índices abaixo do valor central em questão.\\

\noindent
Obs: Município de Vitória não foi incluido nos gráficos pois suas notificações de dengue são extremas o suficiente para fazer esse tipo de gráfico ser inutilizado vizualmente.

\newpage
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=

attach(dados_2013_boxplot)

           ########## urb ##########

#Cria urb_indice
dados_2013_boxplot$urb_indice <- 
  ifelse(urb < 63, 1, 0)

dados_2013_boxplot$urb_indice <- 
  fct_recode(as.factor(dados_2013_boxplot$urb_indice), 
             "sim" = "1",
             "não" = "0")

#Boxplot urb_indice e dengue
ggplot(dados_2013_boxplot[-78,], 
       aes(x = urb_indice,
       y = dengue,
       group = urb_indice, 
       fill = urb_indice)
) + 
  geom_boxplot(notch = FALSE) + 
  scale_y_continuous(breaks = seq(0,20500,500)) + 
  labs(y = "Notificações de dengue\n",
       x = "\nPercentual de urbanização menor do que a media (< 63%) ?") + 
  guides(fill = FALSE) 

detach(dados_2013_boxplot)

@
\textbf{Figura 3:} Boxplot do número de notificações de dengue e o nível de urbanização dos municípios por grupos (maior ou menor que a média).\\

Na \emph{Figura 3}, vemos que o grupo de municípios que possuem um percentual de urbanização maior do que a média, possui mais casos com notificações extremas de dengue, sugerindo talvez, que o nível de urbanização do município tenha relação com notificações de dengue.

\newpage
%%%%%%% Grafico de correlação %%%%%%%

Pensando em todas as variáveis do conjunto de dados, como é a correlação entre elas ?

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,fig.width= 9.5, fig.height= 8>>=
require(ggcorrplot)
corr <- round(cor(dados_2013[,-1]), 1)
ggcorrplot(corr,
           #hc.order = TRUE, 
           type = "upper",
           outline.col = "white", 
           lab = TRUE, 
           lab_size = 3
           )
@
\textbf{Figura 4:} Gráfico de correlação entre as covariáveis.\\

Na \emph{Figura 4} vemos que as variáveis \_pop\_ e \_dens\_ possuem correlação muito alta com nossa variável de interesse, informação valiosa para construção do modelo posteriormente. Além disso, as variáveis de temperatura e umidade também possuem alta correlação com variáveis com as mesmas características como \_temp\_p$90$\_ e \_umid\_p$90$\_, o que é esperado.

\newpage
\section{{\LARGE\textbf{Construção do modelo}}}

A primeira coisa a se fazer para termos um modelo de regressão é verificar se é possível utilizar a regressão linear, sendo que, nesse modelo a nossa variável resposta tem de apresentar uma distribuição aproximadamente normal.

Como temos a nossa variável de interesse como um dado de contagem, sendo esses dados com valores baixos, não é correto que ajustemos um modelo linear simples, sendo então necessário um modelo específico, no caso temos duas distribuições principais que podem ser melhores ajustes:

\begin{itemize}
  \item Poisson
  \item Binomial Negativa
\end{itemize}

\subsection{\textbf{Modelo Poisson}}

Como vimos, a variável independente do modelo possui um formato que condiz com o de uma distribuição Poisson, temos, também que $Y_i$ são independentes $\forall i \leq n$, onde cada unidade experimental é o município.

\subsubsection{\textbf{Definição do modelo}}

Utilizando uma função de ligação logarítmica temos um modelo inicial utilizando todas as variáveis na forma sistemática abaixo

$$log(\lambda_i)=\alpha+\beta_1{x_1}_i+\beta_2{x_2}_i+\cdots+\beta_{26}{x_{26}}_i$$

\subsubsection{\textbf{Modelo considerando todas as covariáveis}}

Ajustando um modelo com todas as $26$ covariáveis e realizando a seleção de variáveis pelo método \_\_AIC\_\_ temos suas informações abaixo:

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=

summary(modelo_selecionado)

@

% FAZER TABELA NO LUGAR DO CHUNK ACIMA DE SER TEMPO.

Vemos que o desvio do resíduo é muito maior que seus graus de liberdade, o que indica um ajuste ruim. Para melhorar nosso modelo vamos reduzir sua dimensão, onde, pela análise descritiva, observamos que algumas covariáveis possuem baixa correlação com a variável resposta \_dengue\_, por esse motivo, as retiramos do modelo, são essas variáveis \_ifdm\_edu\_ e \_area\_.

Para impedir multicolinearidade observamos altas correlações entre pares de covariáveis, sendo as mais altas descritas a seguir:

\begin{table}[H]
\caption{Pares de covariáveis com as correlações mais altas identificadas:} 
\begin{center}
\begin{tabular}{c|c|c}
\hline
Variável 1                         & Variável 2      & Correlação                      \\ \hline
IntCdAtBca                         & $\mathbf{ifdm\_saude}$ & \multicolumn{1}{l}{-0.77960350} \\
temp\_p10                          & \textbf{alt}         & -0.821314067                    \\
temp\_p10                          & \textbf{temp}        & 0.993364738                     \\
temp\_p10                          & $\mathbf{temp\_p90}$   & 0.946850236                     \\
temp                               & $\mathbf{temp\_p90}$   & 0.976276719                     \\
\textbf{temp}                           & \textbf{alt}         & -0.852298080                    \\
$\mathbf{temp\_p90}$                      & alt             & -0.884910605                    \\
\textbf{precip}                         & umid\_p90       & 0.79257030                      \\
umid\_p10                          & \textbf{umid}        & 0.86471582                      \\
\textbf{umid}                           & umid\_p90       & 0.890202356                     \\
umid\_p90                          & \textbf{ivc}         & -0.63608509                     \\
$\mathbf{ifdm\_emprend}$                  & Pobr            & -0.62697421                     \\
Pobr                               & \textbf{adultos}     & -0.708001527                    \\
menor15                            & \textbf{maior65}     & -0.690958203                    \\
menor15                            & \textbf{adultos}     & -0.715345068                    \\
pop                                & \textbf{dens}        & 0.78260681                      \\ \hline
\end{tabular}
\end{center}
\end{table}

Para nosso modelo escolhemos, então, seguir com a variávei mais correlata com a variável resposta entre os pares da tabela acima, o que nos deixou com um modelo com as 15 variáveis abaixo:

\begin{itemize}
  \item CobCondSaud
  \item CobAtencBsca
  \item temp\_p$90$
  \item precip
  \item umid
  \item ifdm\_saude
  \item ifdm\_emprend
  \item cobveg
  \item expcosteira
  \item ivc
  \item ExpAnosEstud
  \item urb
  \item maior$65$
  \item adultos
  \item dens
\end{itemize}


\subsubsection{\textbf{Modelo com seleção de covariáveis}}

Com o modelo descrito acima obtivemos, também com a seleção de variáveis pelo \_AIC\_, os seguintes resultados:

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=

summary(modelo_selecionado_corr)

@

% FAZER TABELA NO LUGAR DO CHUNK ACIMA DE SER TEMPO.

Note que em comparação com o modelo completo, em teoria, pioramos a qualidade do ajuste, porém, tiramos as multicolinearidades, que podem ser observadas na tabela com os VIFs de cada variável por modelo abaixo:

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,fig.pos='H'>>=

tab_mold1 <- knitr::kable(vif(modelo_selecionado), col.names = c("VIF"), caption = "Modelo com variáveis correlatas")

kable_styling(tab_mold1, latex_options = "HOLD_position")

tab_mold2 <- knitr::kable(vif(modelo_selecionado_corr), col.names = c("VIF"), caption = "Modelo sem variáveis correlatas")

kable_styling(tab_mold2, latex_options = "HOLD_position")
@

Seguimos, agora, para a análise do nosso modelo sem as variáveis correlatas, que nos dá os gráficos abaixo:

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=

fit.model <-modelo_selecionado_corr

par(mfrow=c(2,2))
### PREPARANDO OS GRÁFICOS
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit.model,type="pearson")/sqrt(1-h)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
corte.hii<- 2*p/n # corte para elementos da diagonal de H
corte.cook<- qf(0.5,p,n-p) # corte para Distância de Cook
#############################
### ALAVACAGEM / LEVERAGE ###
#############################
plot(fitted(fit.model), 
     h, 
     xlab="Valor Ajustado", 
     ylab="Medida h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylim=c(0,1), 
     pch=20
     )

lines(c(0,max(fitted(fit.model))+1), 
      c(corte.hii,corte.hii), 
      col='red',
      lty=2
      )
# identify(fitted(fit.model), h, n=12)
#########################
### PONTOS INFLUENTES ###
#########################
plot(di, 
     type="h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     xlab="Observação", 
     ylab="Distância de Cook", 
     ylim=c(0,max(max(di),corte.cook))
     )

lines(c(0,n+1), 
      c(corte.cook,corte.cook), 
      col='red', 
      lty=2 
      )
# identify(di, n=6)
############################
### PREDITOR LINEAR VS Z ### p/ verificar adequação da função de ligação
############################
w <- fit.model$weights
eta <- predict(fit.model)
z <- eta + resid(fit.model, type="pearson")/sqrt(w)

plot(predict(fit.model), 
     z, 
     xlab="Preditor Linear", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylab="Variavel z", 
     pch=20
     )

lines(smooth.spline(predict(fit.model), z, df=2))
################
### ENVELOPE ###
################
e <- matrix(0,n,1000)
#
for(i in 1:1000){
  nresp <- rpois(n, fitted(fit.model))
  fit <- glm(nresp ~ X, family=poisson)
  w <- fit$weights
  W <- diag(w)
  H <- solve(t(X)%*%W%*%X)
  H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
  h <- diag(H)
  e[,i] <- sort(resid(fit,type="deviance")/sqrt(1-h))}
#
e1 <- numeric(n)
e2 <- numeric(n)
#
for(i in 1:n){
  eo <- sort(e[i,])
  e1[i] <- eo[25]
  e2[i] <- eo[975]}
#
med <- apply(e,1,mean)
faixa <- range(td,e1,e2)
#
qqnorm(td, 
       xlab="Percentil da N(0,1)",
       ylab="Componente do Desvio",
       ylim=faixa, 
       cex.lab=1.5, 
       cex.axis=1.5,
       pch=20,
       main=""
       )
par(new=TRUE)
#
qqnorm(e1,axes=F,xlab="",ylab="",type="l",ylim=faixa,lty=1, main="")
par(new=TRUE)
qqnorm(e2,axes=F,xlab="",ylab="", type="l",ylim=faixa,lty=1, main="")
par(new=TRUE)
qqnorm(med,axes=F,xlab="", ylab="", type="l",ylim=faixa,lty=2, main="")
@
\textbf{Figura :} Gráficos de diagnóstico para o modelo sem \_offset\_.

Como é possível observar pelos gráficos da \emph{Figura}, principalmente pelo gráfico de envelope dos resíduos, temos um modelo superdisperso, o que tentaremos resolver acrescentando um \_offset\_.

\subsubsection{\textbf{Modelo com \_Offset\_}}

Para adicionarmos um dado \_offset\_ no modelo vemos que ele pode ser a variável \_pop\_, que indica uma alta variabilidade do tamanho das populações nos municípios. Segue o modelo:

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
 
# stargazer(modelo_selecionado_corr_offset, table.placement = "H", no.space = TRUE, keep.stat = c("res.dev","aic"))

summary(modelo_selecionado_corr_offset)

@

% FAZER TABELA NO LUGAR DO SGUNK ACIMA DE SER TEMPO
\newpage
Vemos que, ainda que tenhamos adicionado o dado \_offset\_, continuamos com um desvio do resíduo super alto, o que significa que o ajuste segue impróprio para o modelo, o que vamos confirmar com a análise dos gráficos do modelo:

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=

fit.model2 <- modelo_selecionado_corr_offset
par(mfrow=c(2,2))
### PREPARANDO OS GRÁFICOS
X <- model.matrix(fit.model2)
n <- nrow(X)
p <- ncol(X)
w <- fit.model2$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit.model2,type="pearson")/sqrt(1-h)
td <- resid(fit.model2,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
corte.hii<- 2*p/n # corte para elementos da diagonal de H
corte.cook<- qf(0.5,p,n-p) # corte para Distância de Cook
#############################
### ALAVACAGEM / LEVERAGE ###
#############################
plot(fitted(fit.model2), h,xlab="Valor Ajustado", ylab="Medida
h",cex.lab=1.5,cex.axis=1.5,
     ylim=c(0,1),pch=20)
lines(c(0,max(fitted(fit.model2))+1),c(corte.hii,corte.hii),col='red',
      lty=2)
#########################
### PONTOS INFLUENTES ###
#########################
plot(di,type="h",cex.lab=1.5,cex.axis=1.5,xlab="Observação",ylab="Dist. de Cook",ylim=c(0,max(max(di),corte.cook)))
lines(c(0,n+1),c(corte.cook,corte.cook),col='red',lty=2)
############################
### PREDITOR LINEAR VS Z ### p/ verificar adequação da função de ligação
############################
w <- fit.model2$weights
eta <- predict(fit.model2)
z <- eta + resid(fit.model2, type="pearson")/sqrt(w)
plot(predict(fit.model2),z,xlab="Preditor
Linear",cex.lab=1.5,cex.axis=1.5, 
     ylab="Variavel z", pch=20)
lines(smooth.spline(predict(fit.model2), z, df=2))
################
### ENVELOPE ###
################
e <- matrix(0,n,1000)
#
for(i in 1:1000){
  nresp <- rpois(n, fitted(fit.model2))
  fit <- glm(nresp ~ X, family=poisson)
  w <- fit$weights
  W <- diag(w)
  H <- solve(t(X)%*%W%*%X)
  H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
  h <- diag(H)
  e[,i] <- sort(resid(fit,type="deviance")/sqrt(1-h))}
#
e1 <- numeric(n)
e2 <- numeric(n)
#
for(i in 1:n){
  eo <- sort(e[i,])
  e1[i] <- eo[25]
  e2[i] <- eo[975]}
#
med <- apply(e,1,mean)
faixa <- range(td,e1,e2)
#
qqnorm(td, 
       xlab="Percentil da N(0,1)",
       ylab="Componente do Desvio",
       ylim=faixa, 
       cex.lab=1.5, 
       cex.axis=1.5,
       pch=20,
       main=""
       )
par(new=TRUE)
#
qqnorm(e1,axes=F,xlab="",ylab="",type="l",ylim=faixa,lty=1, main="")
par(new=TRUE)
qqnorm(e2,axes=F,xlab="",ylab="", type="l",ylim=faixa,lty=1, main="")
par(new=TRUE)
qqnorm(med,axes=F,xlab="", ylab="", type="l",ylim=faixa,lty=2, main="")

@
\textbf{Figura :} Gráficos de diagnóstico para o modelo com \_offset\_.

\newpage
\subsubsection{\textbf{Interpretação e conclusões}}

Pudemos observar que, mesmo manipulando nosso modelo, continuamos com um ajuste ruim, visto que temos um desvio residual muito maior que os graus de liberdade. Outro indício disso é a sobredispersão observada no gráfico de envelope, o que podemos imaginar que ocorreria, uma vez que temos a média da nossa variável resposta dengue consideravelmente diferente da sua variância, o que não deveria ocorrer, uma vez que a distribuição de Poisson teórica possui média e variância iguais.

Tais constatações nos levam a descartar o modelo Poisson e tentar o ajuste por um modelo Binomial Negativo.

%%%%%%Modelos
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,include=FALSE>>=

########## modelos definidos ###########

##### bn


dados <- read_excel("dados.xlsx")
dados_2013 <- subset(dados,ano == 2013)
dados_2013 <- dados_2013[,-28] #sem id

modelo_completo_bn <- glm.nb(dengue~IntCdAtBca +
                        CobCondSaud +
                        CobAtencBsca +
                        temp_p10 +
                        temp +
                        temp_p90 +
                        precip +
                        umid_p10 +
                        umid +
                        umid_p90 +
                        alt +
                        ifdm_saude +
                        ifdm_edu +
                        ifdm_emprend +
                        cobveg +
                        expcosteira +
                        ivc +
                        Pobr +
                        ExpAnosEstud +
                        urb +
                        menor15 +
                        maior65 +
                        adultos +
                        pop +
                        area +
                        dens, 
                        control = 
                          glm.control(maxit = 50), 
                        data = dados
                       )

modelo_selecionado_bn <- stepAIC(modelo_completo_bn)

modelo_corr_bn<- glm.nb(dengue~CobCondSaud +
                         CobAtencBsca +
                         temp_p90 + 
                         precip +
                         umid +
                         ifdm_saude +
                         ifdm_emprend +
                         cobveg +
                         expcosteira +
                         ivc + 
                         ExpAnosEstud +
                         urb + 
                         maior65 + 
                         adultos +
                         dens +
                         pop,
                       control = 
                         glm.control(maxit = 50), 
                       data = dados_2013
                       )
modelo_selecionado_corr_bn <- stepAIC(modelo_corr_bn)
 
modelo_corr_offset_nb<- glm.nb(dengue~CobCondSaud +
                         CobAtencBsca +
                         temp_p90 + 
                         precip +
                         umid +
                         ifdm_saude +
                         ifdm_emprend +
                         cobveg +
                         expcosteira +
                         ivc + 
                         ExpAnosEstud +
                         urb + 
                         maior65 + 
                         adultos +
                         dens +
                         offset(log(pop)),
                       control = 
                         glm.control(maxit = 50), 
                       data = dados_2013
                       )

modelo_selecionado_corr_offset_bn <- stepAIC(modelo_corr_offset_nb)

@
\subsection{\textbf{Modelo Binomial Negativo}}
O modelo Binomial Negativo por definição não é MLG, entretanto, possui características muito semelhantes e possui uma boa capacidade de capturar um efeito $E(Y_i)<Var(Y_i)$. Que é exatamente o problema encontrado acima.
\subsubsection{\textbf{Definição do modelo}}
Utilizando uma função de ligação logarítmica temos um modelo inicial utilizando todas as variáveis na forma sistemática abaixo

$$log(\lambda_i)=\alpha+\beta_1{x_1}_i+\beta_2{x_2}_i+\cdots+\beta_{26}{x_{26}}_i$$
\subsubsection{\textbf{Modelo considerando todas covariáveis}}
Ajustando um modelo com todas as 26 covariáveis e realizando a seleção de variáveis pelo método AIC temos suas informações abaixo:
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=

summary(modelo_selecionado_bn)

@
Como aconteceu com o Modelo Poisson, é possivel perceber, com base no desvio residual que o ajuste é ruim. Para corrir isso, faremos o mesmo que foi feito com o Modelo Poisson, ou seja, usaremos as 15 variáveis mais correlatadas com a variável resposta, sendo elas:

\begin{itemize}
  \item CobCondSaud
  \item CobAtencBsca
  \item temp\_p$90$
  \item precip
  \item umid
  \item ifdm\_saude
  \item ifdm\_emprend
  \item cobveg
  \item expcosteira
  \item ivc
  \item ExpAnosEstud
  \item urb
  \item maior$65$
  \item adultos
  \item dens
\end{itemize}

\subsubsection{\textbf{Modelo com seleção de covariáveis}}

Com o modelo descrito acima obtivemos, também com a seleção de variáveis pelo \_AIC\_, os seguintes resultados:
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=

summary(modelo_selecionado_corr_bn)

@
Perceba que, com a escolha de variáveis acima, melhoramos bastante o ajuste do modelo. Gerando os gráficos para o modelo acima, obtemos:
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
fit.model <- modelo_selecionado_corr_bn

par(mfrow=c(2,2))
### PREPARANDO OS GRÁFICOS
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
fi <- fit.model$theta
#w <- fi*fitted(fit.model)/(fi + fitted(fit.model))
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit.model,type="pearson")/sqrt(1-h)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
corte.hii<- 2*p/n # corte para elementos da diagonal de

corte.cook<- qf(0.5,p,n-p) # corte para Distância de Cook
#############################
### ALAVACAGEM / LEVERAGE ###
#############################
plot(fitted(fit.model), 
     h, 
     xlab="Valor Ajustado", 
     ylab="Medida h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylim=c(0,1), 
     pch=20
     )

lines(c(0,max(fitted(fit.model))+1), 
      c(corte.hii,corte.hii), 
      col='red',
      lty=2
      )
#identify(fitted(fit.model), h, n=1)
#########################
### PONTOS INFLUENTES ###
#########################
plot(di, 
     type="h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     xlab="Observação", 
     ylab="Distância de Cook", 
     ylim=c(0,max(max(di),corte.cook))
     )

lines(c(0,n+1),c(corte.cook,corte.cook),col='red',lty=2)
#identify(di, n=1)
############################
### PREDITOR LINEAR VS Z ### p/ verificar adequação da função de ligação
############################
eta <- predict(fit.model)
z <- eta + resid(fit.model, type="pearson")/sqrt(w)

plot(predict(fit.model), 
     z, 
     xlab="Preditor Linear", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylab="Variavel z", 
     pch=20
     )

lines(smooth.spline(predict(fit.model), z, df=2))
################
### ENVELOPE ###
################

# dev.new(width=6,height=3)
hnp(fit.model, 
    xlab = 'Percentil da N(0,1)',
    ylab = 'Resíduos', 
    main = 'Gráfico Normal de Probabilidades', 
    pch = 20, 
    cex.lab=1.5, 
    cex.axis=1.5
    )

@

\subsubsection{\textbf{Modelo com \_Offset\_}}
Agora, colocando a variável \_pop\_ como \_Offset\_
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
 
# stargazer(modelo_selecionado_corr_offset, table.placement = "H", no.space = TRUE, keep.stat = c("res.dev","aic"))

summary(modelo_selecionado_corr_offset_bn)

@
A escolha de deixar a variável \_pop\_ como \_Offset\_ melhorou o ajuste do modelo, visto que o desvio residual se aproximou um pouco mais dos graus de liberdade, abaixo, temos os gráficos do modelo com \_Offset\_:
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=

fit.model <- modelo_selecionado_corr_offset_bn
par(mfrow=c(2,2))
### PREPARANDO OS GRÁFICOS
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
fi <- fit.model$theta
#w <- fi*fitted(fit.model)/(fi + fitted(fit.model))
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit.model,type="pearson")/sqrt(1-h)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
corte.hii<- 2*p/n # corte para elementos da diagonal de
corte.cook<- qf(0.5,p,n-p) # corte para Distância de Cook
#############################
### ALAVACAGEM / LEVERAGE ###
#############################
plot(fitted(fit.model), 
     h, 
     xlab="Valor Ajustado", 
     ylab="Medida h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylim=c(0,1), 
     pch=20
     )

lines(c(0,max(fitted(fit.model))+1), 
      c(corte.hii,corte.hii), 
      col='red',
      lty=2
      )
#identify(fitted(fit.model), h, n=1)
#########################
### PONTOS INFLUENTES ###
#########################
plot(di, 
     type="h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     xlab="Observação", 
     ylab="Distância de Cook", 
     ylim=c(0,max(max(di),corte.cook))
     )

lines(c(0,n+1),c(corte.cook,corte.cook),col='red',lty=2)
#identify(di, n=1)
############################
### PREDITOR LINEAR VS Z ### p/ verificar adequação da função de ligação
############################
eta <- predict(fit.model)
z <- eta + resid(fit.model, type="pearson")/sqrt(w)

plot(predict(fit.model), 
     z, 
     xlab="Preditor Linear", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylab="Variavel z", 
     pch=20
     )

lines(smooth.spline(predict(fit.model), z, df=2))
################
### ENVELOPE ###
################

# dev.new(width=6,height=3)
hnp(fit.model, 
    xlab = 'Percentil da N(0,1)',
    ylab = 'Resíduos', 
    main = 'Gráfico Normal de Probabilidades', 
    pch = 20, 
    cex.lab=1.5, 
    cex.axis=1.5
    )

@
\subsubsection{\textbf{Sobre a remoção de pontos influentes}}
Usando a funçao identify, identificamos pontos influentes, entretanto, preferimos por não remove-los no modelo final, já que em nosso subset temos apenas 78 linhas.
Abaixo, alguns resultados que obtivemos na remoção de alguns pontos influentes:
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
##Uma remocao
dados_2013_1<- dados_2013[-44,]
modelo_corr_offset_nb<- glm.nb(dengue~CobCondSaud +
                         CobAtencBsca +
                         temp_p90 + 
                         precip +
                         umid +
                         ifdm_saude +
                         ifdm_emprend +
                         cobveg +
                         expcosteira +
                         ivc + 
                         ExpAnosEstud +
                         urb + 
                         maior65 + 
                         adultos +
                         dens +
                         offset(log(pop)),
                       control = glm.control(maxit = 50), 
                       data = dados_2013_1
                       )



@

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,include=FALSE>>=
modelo_selecionado_corr_offset_bn <- stepAIC(modelo_corr_offset_nb)
@

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
summary(modelo_selecionado_corr_offset_bn)
fit.model <- modelo_selecionado_corr_offset_bn
par(mfrow=c(2,2))
### PREPARANDO OS GRÁFICOS
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
fi <- fit.model$theta
#w <- fi*fitted(fit.model)/(fi + fitted(fit.model))
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit.model,type="pearson")/sqrt(1-h)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
corte.hii<- 2*p/n # corte para elementos da diagonal de
corte.cook<- qf(0.5,p,n-p) # corte para Distância de Cook
#############################
### ALAVACAGEM / LEVERAGE ###
#############################
plot(fitted(fit.model), 
     h, 
     xlab="Valor Ajustado", 
     ylab="Medida h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylim=c(0,1), 
     pch=20
     )

lines(c(0,max(fitted(fit.model))+1), 
      c(corte.hii,corte.hii), 
      col='red',
      lty=2
      )
#identify(fitted(fit.model), h, n=1)
#########################
### PONTOS INFLUENTES ###
#########################
plot(di, 
     type="h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     xlab="Observação", 
     ylab="Distância de Cook", 
     ylim=c(0,max(max(di),corte.cook))
     )

lines(c(0,n+1),c(corte.cook,corte.cook),col='red',lty=2)
#identify(di, n=1)
############################
### PREDITOR LINEAR VS Z ### p/ verificar adequação da função de ligação
############################
eta <- predict(fit.model)
z <- eta + resid(fit.model, type="pearson")/sqrt(w)

plot(predict(fit.model), 
     z, 
     xlab="Preditor Linear", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylab="Variavel z", 
     pch=20
     )

lines(smooth.spline(predict(fit.model), z, df=2))
################
### ENVELOPE ###
################

# dev.new(width=6,height=3)
hnp(fit.model, 
    xlab = 'Percentil da N(0,1)',
    ylab = 'Resíduos', 
    main = 'Gráfico Normal de Probabilidades', 
    pch = 20, 
    cex.lab=1.5, 
    cex.axis=1.5
    )
@

\textbf{Figura :} Gráficos de diagnóstico para uma remoção.
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,results=FALSE>>=
##duas remocoes
dados_2013_1<- dados_2013_1[-73,]
modelo_corr_offset_nb<- glm.nb(dengue~CobCondSaud +
                         CobAtencBsca +
                         temp_p90 + 
                         precip +
                         umid +
                         ifdm_saude +
                         ifdm_emprend +
                         cobveg +
                         expcosteira +
                         ivc + 
                         ExpAnosEstud +
                         urb + 
                         maior65 + 
                         adultos +
                         dens +
                         offset(log(pop)),
                       control = glm.control(maxit = 50), 
                       data = dados_2013_1
                       )


@

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,include=FALSE>>=
modelo_selecionado_corr_offset_bn <- stepAIC(modelo_corr_offset_nb)
@

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
summary(modelo_selecionado_corr_offset_bn)

fit.model <- modelo_selecionado_corr_offset_bn
par(mfrow=c(2,2))
### PREPARANDO OS GRÁFICOS
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
fi <- fit.model$theta
#w <- fi*fitted(fit.model)/(fi + fitted(fit.model))
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit.model,type="pearson")/sqrt(1-h)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
corte.hii<- 2*p/n # corte para elementos da diagonal de
corte.cook<- qf(0.5,p,n-p) # corte para Distância de Cook
#############################
### ALAVACAGEM / LEVERAGE ###
#############################
plot(fitted(fit.model), 
     h, 
     xlab="Valor Ajustado", 
     ylab="Medida h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylim=c(0,1), 
     pch=20
     )

lines(c(0,max(fitted(fit.model))+1), 
      c(corte.hii,corte.hii), 
      col='red',
      lty=2
      )
#identify(fitted(fit.model), h, n=1)
#########################
### PONTOS INFLUENTES ###
#########################
plot(di, 
     type="h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     xlab="Observação", 
     ylab="Distância de Cook", 
     ylim=c(0,max(max(di),corte.cook))
     )

lines(c(0,n+1),c(corte.cook,corte.cook),col='red',lty=2)
#identify(di, n=1)
############################
### PREDITOR LINEAR VS Z ### p/ verificar adequação da função de ligação
############################
eta <- predict(fit.model)
z <- eta + resid(fit.model, type="pearson")/sqrt(w)

plot(predict(fit.model), 
     z, 
     xlab="Preditor Linear", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylab="Variavel z", 
     pch=20
     )

lines(smooth.spline(predict(fit.model), z, df=2))
################
### ENVELOPE ###
################

# dev.new(width=6,height=3)
hnp(fit.model, 
    xlab = 'Percentil da N(0,1)',
    ylab = 'Resíduos', 
    main = 'Gráfico Normal de Probabilidades', 
    pch = 20, 
    cex.lab=1.5, 
    cex.axis=1.5
    )

@
\textbf{Figura :} Gráficos de diagnóstico para duas remoção.

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
##tres remocoes
dados_2013_1<- dados_2013_1[-5,]
modelo_corr_offset_nb<- glm.nb(dengue~CobCondSaud +
                         CobAtencBsca +
                         temp_p90 + 
                         precip +
                         umid +
                         ifdm_saude +
                         ifdm_emprend +
                         cobveg +
                         expcosteira +
                         ivc + 
                         ExpAnosEstud +
                         urb + 
                         maior65 + 
                         adultos +
                         dens +
                         offset(log(pop)),
                       control = glm.control(maxit = 50), 
                       data = dados_2013_1
                       )



@

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,include=FALSE>>=
modelo_selecionado_corr_offset_bn <- stepAIC(modelo_corr_offset_nb)
@

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
summary(modelo_selecionado_corr_offset_bn)
fit.model <- modelo_selecionado_corr_offset_bn
par(mfrow=c(2,2))
### PREPARANDO OS GRÁFICOS
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
fi <- fit.model$theta
#w <- fi*fitted(fit.model)/(fi + fitted(fit.model))
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit.model,type="pearson")/sqrt(1-h)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
corte.hii<- 2*p/n # corte para elementos da diagonal de
corte.cook<- qf(0.5,p,n-p) # corte para Distância de Cook
#############################
### ALAVACAGEM / LEVERAGE ###
#############################
plot(fitted(fit.model), 
     h, 
     xlab="Valor Ajustado", 
     ylab="Medida h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylim=c(0,1), 
     pch=20
     )

lines(c(0,max(fitted(fit.model))+1), 
      c(corte.hii,corte.hii), 
      col='red',
      lty=2
      )
#identify(fitted(fit.model), h, n=1)
#########################
### PONTOS INFLUENTES ###
#########################
plot(di, 
     type="h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     xlab="Observação", 
     ylab="Distância de Cook", 
     ylim=c(0,max(max(di),corte.cook))
     )

lines(c(0,n+1),c(corte.cook,corte.cook),col='red',lty=2)
#identify(di, n=1)
############################
### PREDITOR LINEAR VS Z ### p/ verificar adequação da função de ligação
############################
eta <- predict(fit.model)
z <- eta + resid(fit.model, type="pearson")/sqrt(w)

plot(predict(fit.model), 
     z, 
     xlab="Preditor Linear", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylab="Variavel z", 
     pch=20
     )

lines(smooth.spline(predict(fit.model), z, df=2))
################
### ENVELOPE ###
################

# dev.new(width=6,height=3)
hnp(fit.model, 
    xlab = 'Percentil da N(0,1)',
    ylab = 'Resíduos', 
    main = 'Gráfico Normal de Probabilidades', 
    pch = 20, 
    cex.lab=1.5, 
    cex.axis=1.5
    )
@
\textbf{Figura :} Gráficos de diagnóstico para tres remoções.
<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
##quatro remocoes
dados_2013_1<- dados_2013_1[-41,]
modelo_corr_offset_nb<- glm.nb(dengue~CobCondSaud +
                         CobAtencBsca +
                         temp_p90 + 
                         precip +
                         umid +
                         ifdm_saude +
                         ifdm_emprend +
                         cobveg +
                         expcosteira +
                         ivc + 
                         ExpAnosEstud +
                         urb + 
                         maior65 + 
                         adultos +
                         dens +
                         offset(log(pop)),
                       control = glm.control(maxit = 50), 
                       data = dados_2013_1
                       )


@

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,include=FALSE>>=
modelo_selecionado_corr_offset_bn <- stepAIC(modelo_corr_offset_nb)
@


<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
summary(modelo_selecionado_corr_offset_bn)
fit.model <- modelo_selecionado_corr_offset_bn
par(mfrow=c(2,2))
### PREPARANDO OS GRÁFICOS
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
fi <- fit.model$theta
#w <- fi*fitted(fit.model)/(fi + fitted(fit.model))
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit.model,type="pearson")/sqrt(1-h)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
corte.hii<- 2*p/n # corte para elementos da diagonal de
corte.cook<- qf(0.5,p,n-p) # corte para Distância de Cook
#############################
### ALAVACAGEM / LEVERAGE ###
#############################
plot(fitted(fit.model), 
     h, 
     xlab="Valor Ajustado", 
     ylab="Medida h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylim=c(0,1), 
     pch=20
     )

lines(c(0,max(fitted(fit.model))+1), 
      c(corte.hii,corte.hii), 
      col='red',
      lty=2
      )
#identify(fitted(fit.model), h, n=1)
#########################
### PONTOS INFLUENTES ###
#########################
plot(di, 
     type="h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     xlab="Observação", 
     ylab="Distância de Cook", 
     ylim=c(0,max(max(di),corte.cook))
     )

lines(c(0,n+1),c(corte.cook,corte.cook),col='red',lty=2)
#identify(di, n=1)
############################
### PREDITOR LINEAR VS Z ### p/ verificar adequação da função de ligação
############################
eta <- predict(fit.model)
z <- eta + resid(fit.model, type="pearson")/sqrt(w)

plot(predict(fit.model), 
     z, 
     xlab="Preditor Linear", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylab="Variavel z", 
     pch=20
     )

lines(smooth.spline(predict(fit.model), z, df=2))
################
### ENVELOPE ###
################

# dev.new(width=6,height=3)
hnp(fit.model, 
    xlab = 'Percentil da N(0,1)',
    ylab = 'Resíduos', 
    main = 'Gráfico Normal de Probabilidades', 
    pch = 20, 
    cex.lab=1.5, 
    cex.axis=1.5
    )
@
\textbf{Figura :} Gráficos de diagnóstico para quatro remoções.


Como optamos por manter os pontos influentes o modelo e os gráficos de analise ficaram da seguinte forma:


<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE,include=FALSE>>=
dados <- read_excel("dados.xlsx")
dados_2013 <- subset(dados,ano == 2013)
dados_2013 <- dados_2013[,-28] #sem id

modelo_corr_offset_nb<- glm.nb(dengue~CobCondSaud +
                                 CobAtencBsca +
                                 temp_p90 + 
                                 precip +
                                 umid +
                                 ifdm_saude +
                                 ifdm_emprend +
                                 cobveg +
                                 expcosteira +
                                 ivc + 
                                 ExpAnosEstud +
                                 urb + 
                                 maior65 + 
                                 adultos +
                                 dens +
                                 offset(log(pop)),
                               control = glm.control(maxit = 50), 
                               data = dados_2013
)

modelo_selecionado_corr_offset_bn <- stepAIC(modelo_corr_offset_nb)
@

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
 
# stargazer(modelo_selecionado_corr_offset, table.placement = "H", no.space = TRUE, keep.stat = c("res.dev","aic"))

summary(modelo_selecionado_corr_offset_bn)

@

<<comment=NA,warning=FALSE,echo=FALSE,message=FALSE>>=
fit.model <- modelo_selecionado_corr_offset_bn
par(mfrow=c(2,2))
### PREPARANDO OS GRÁFICOS
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
fi <- fit.model$theta
#w <- fi*fitted(fit.model)/(fi + fitted(fit.model))
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit.model,type="pearson")/sqrt(1-h)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
corte.hii<- 2*p/n # corte para elementos da diagonal de
corte.cook<- qf(0.5,p,n-p) # corte para Distância de Cook
#############################
### ALAVACAGEM / LEVERAGE ###
#############################
plot(fitted(fit.model), 
     h, 
     xlab="Valor Ajustado", 
     ylab="Medida h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylim=c(0,1), 
     pch=20
     )

lines(c(0,max(fitted(fit.model))+1), 
      c(corte.hii,corte.hii), 
      col='red',
      lty=2
      )
#identify(fitted(fit.model), h, n=1)
#########################
### PONTOS INFLUENTES ###
#########################
plot(di, 
     type="h", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     xlab="Observação", 
     ylab="Distância de Cook", 
     ylim=c(0,max(max(di),corte.cook))
     )

lines(c(0,n+1),c(corte.cook,corte.cook),col='red',lty=2)
#identify(di, n=1)
############################
### PREDITOR LINEAR VS Z ### p/ verificar adequação da função de ligação
############################
eta <- predict(fit.model)
z <- eta + resid(fit.model, type="pearson")/sqrt(w)

plot(predict(fit.model), 
     z, 
     xlab="Preditor Linear", 
     cex.lab=1.5, 
     cex.axis=1.5, 
     ylab="Variavel z", 
     pch=20
     )

lines(smooth.spline(predict(fit.model), z, df=2))
################
### ENVELOPE ###
################

# dev.new(width=6,height=3)
hnp(fit.model, 
    xlab = 'Percentil da N(0,1)',
    ylab = 'Resíduos', 
    main = 'Gráfico Normal de Probabilidades', 
    pch = 20, 
    cex.lab=1.5, 
    cex.axis=1.5
    )

@
Podemos percerber pelos gráficos que o ajuste foi bem feito, muito diferente de quando utilizamos a Poisson.
\subsubsection{\textbf{Interpretação e conclusões}}
Pelo ajuste do modelo final, podemos verificar que de fato, o Modelo Binomial Negativo, se adequou aos dados, já que os dados tinham alta variabilidade em relação média, motivo, que levou o descarte do modelo Poisson.
\end{document}